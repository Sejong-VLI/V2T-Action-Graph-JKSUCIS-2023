{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103cf79-ac04-4ee2-935a-123fff56a187",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import h5py\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.ops.roi_align as roi_align\n",
    "from itertools import permutations\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Arguments\n",
    "class args:\n",
    "    msvd = True # for MSR-VTT change this to False\n",
    "    num_features_logits = 1024\n",
    "    slice_framepos=2\n",
    "    root ='./'\n",
    "    dset ='../' # change based on dataset location\n",
    "    save_path = '../../extracted'\n",
    "    max_frames = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run I3D notebook\n",
    "%run ./model/i3d/i3d.ipynb import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load I3D model\n",
    "i3d = InceptionI3d(400, in_channels=3)\n",
    "# pretrained model is downloaded from here: https://github.com/piergiaj/pytorch-i3d\n",
    "i3d.load_state_dict(torch.load(os.path.join(args.root, 'pretrained', 'rgb_imagenet.pt')))\n",
    "i3d = i3d.to(device)\n",
    "i3d.eval()\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess video\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "data_transform_fasterrcnn = transforms.Compose([transforms.ToTensor()])\n",
    "data_transform_i3d = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess video\n",
    "if args.msvd:\n",
    "\n",
    "    dset_path = os.path.join(os.path.join(args.dset,'dataset'),'MSVD')\n",
    "\n",
    "    features_path = os.path.join(dset_path,'raw') # video .avi\n",
    "    name_list = glob.glob(features_path+os.sep+'*')\n",
    "\n",
    "    url2id = {}\n",
    "    data_path =os.path.join(os.path.join(dset_path,'captions','youtube_mapping.txt'))\n",
    "    for line in open(data_path,'r').readlines():\n",
    "        url2id[line.strip().split(' ')[0]] = line.strip().split(' ')[-1]\n",
    "\n",
    "\n",
    "    path_to_saved_models = \"extracted/msvd\"\n",
    "    pathlib.Path(path_to_saved_models).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "else:\n",
    "\n",
    "    dset_path = os.path.join(os.path.join(args.dset,'dataset'),'MSRVTT')\n",
    "    features_path = os.path.join(dset_path,'raw')\n",
    "\n",
    "    name_list = glob.glob(features_path+os.sep+'*')\n",
    "    path_to_saved_models = \"extracted/msrvtt\"\n",
    "    pathlib.Path(path_to_saved_models).mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def video2tensor(video_file,sample_fp=1, start_time=None, end_time=None):\n",
    "    if start_time is not None or end_time is not None:\n",
    "        assert isinstance(start_time, int) and isinstance(end_time, int) \\\n",
    "               and start_time > -1 and end_time > start_time\n",
    "    assert sample_fp > -1\n",
    "    # Samples a frame sample_fp X frames.\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    total_duration = (frameCount + fps - 1) // fps\n",
    "    start_sec, end_sec = 0, total_duration\n",
    "\n",
    "\n",
    "\n",
    "    interval = 1\n",
    "    if sample_fp > 0:\n",
    "        interval = fps // sample_fp\n",
    "    else:\n",
    "        sample_fp = fps\n",
    "    if interval == 0: interval = 1\n",
    "\n",
    "    inds = [ind for ind in np.arange(0, fps, interval)]\n",
    "    inds_all = [ind for ind in np.arange(0, fps, 1)]\n",
    "    assert len(inds) >= sample_fp\n",
    "    inds = inds[:sample_fp]\n",
    "    inds = set(inds)\n",
    "    ret = True\n",
    "    images_fasterrcnn,images_i3d, included = [], [], []\n",
    "    c = 0\n",
    "    sampled_indexes = []\n",
    "    for sec in np.arange(start_sec, end_sec + 1):\n",
    "        if not ret: break\n",
    "        # sec_base = int(sec * fps)\n",
    "        for ia in inds_all:\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil = Image.fromarray(frame_rgb).convert(\"RGB\")\n",
    "            if ia in inds:\n",
    "                sampled_indexes.append(c)\n",
    "                images_fasterrcnn.append(data_transform_fasterrcnn(pil))\n",
    "            images_i3d.append(data_transform_i3d(pil))\n",
    "            c+=1\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    tensor_fasterrcnn = None\n",
    "    if len(images_fasterrcnn) > 0:\n",
    "        video_data_fasterrcnn = torch.tensor(np.stack(images_fasterrcnn))\n",
    "        #process raw data section\n",
    "        tensor_size = video_data_fasterrcnn.size()\n",
    "\n",
    "        tensor_fasterrcnn = video_data_fasterrcnn.view(-1, 1, tensor_size[-3], tensor_size[-2], tensor_size[-1])\n",
    "\n",
    "        video_data_i3d = torch.tensor(np.stack(images_i3d))\n",
    "        #process raw data section\n",
    "        tensor_size = video_data_i3d.size()\n",
    "        tensor_i3d = video_data_i3d.view(-1, 1, tensor_size[-3], tensor_size[-2], tensor_size[-1])\n",
    "    else:\n",
    "        video_data = torch.zeros(1)\n",
    "\n",
    "\n",
    "    return tensor_fasterrcnn,tensor_i3d, sampled_indexes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Spatial Graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c1dba-7bed-4644-905d-2edc35a48e3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FILE_FO = \"<Path to the extracted object node features>\"\n",
    "save_file = path_to_saved_models + '/<Desired file name>.hdf5'\n",
    "NUM_OBJECT = 9\n",
    "frame_num = 16\n",
    "with torch.no_grad():\n",
    "    with h5py.File(FILE_FO, 'r') as fo, h5py.File(save_file, 'w') as f:\n",
    "        for name in tqdm(name_list):\n",
    "            tensor_fasterrcnn,tensor_i3d, sampled_indices = video2tensor(name)\n",
    "            sample_indx =[]\n",
    "            if args.max_frames < tensor_fasterrcnn.shape[0]:\n",
    "                if args.slice_framepos == 0:\n",
    "                    video_slice = raw_video_slice[:args.max_frames, ...]\n",
    "                elif args.slice_framepos == 1:\n",
    "                    video_slice = raw_video_slice[-args.max_frames:, ...]\n",
    "                else:\n",
    "                    sample_indx = list(np.linspace(0, tensor_fasterrcnn.shape[0] - 1, num=args.max_frames, dtype=int))\n",
    "                 \n",
    "            else:\n",
    "                sample_indx = list(np.arange(tensor_fasterrcnn.shape[0]))\n",
    "\n",
    "           \n",
    "\n",
    "            if(len(sample_indx)<args.max_frames):\n",
    "                additional = 20-len(sample_indx)\n",
    "                sample_indx += (additional * [-1])\n",
    "            \n",
    "            for idx_grp, i in enumerate(sample_indx):\n",
    "                if args.msvd:\n",
    "                    ide = url2id[name.split(os.sep)[-1].split('.')[0]]\n",
    "                else:\n",
    "                    ide = name.split(os.sep)[-1].split('.')[0]\n",
    "            \n",
    "            \n",
    "                zero = np.array([0.0]*args.num_features_logits)\n",
    "                Gs_temp = [[zero]* NUM_OBJECT for m in range(NUM_OBJECT)]\n",
    "                \n",
    "                if (i==-1):\n",
    "                    f.create_dataset(ide+'-'+str(idx_grp), data = Gs_temp)# for each frame\n",
    "                    continue\n",
    "              \n",
    "                i_i3d = (sampled_indices[i]//frame_num)*frame_num\n",
    "                if len(tensor_i3d)-i_i3d < frame_num:\n",
    "                    i_i3d = len(tensor_i3d)-frame_num\n",
    "                    \n",
    "                curr_batch = tensor_i3d[i_i3d:i_i3d+frame_num,...].unsqueeze(0)\n",
    "                n,video_frame,num,channel,h,w = curr_batch.shape\n",
    "                curr_batch = curr_batch.view(num,video_frame,channel, h, w)\n",
    "                curr_batch = curr_batch.permute(0,2,1,3,4)\n",
    "           \n",
    "\n",
    "                \n",
    "                out_logits = i3d.extract_features(curr_batch.to(device))\n",
    "            \n",
    "                out_logits= out_logits[:,:,0,0,0]\n",
    "                out_logits = out_logits.cpu().numpy()\n",
    "                \n",
    "                obj = fo[ide+'-'+str(idx_grp)][:]\n",
    "\n",
    "                \n",
    "                for k in range(NUM_OBJECT):\n",
    "                    for l in range(k, NUM_OBJECT):\n",
    "                        sum_k = np.sum(obj[k])\n",
    "                        sum_l = np.sum(obj[l])\n",
    "                        if (sum_k!=0 and sum_l!=0):\n",
    "                            Gs_temp[k][l] = out_logits.tolist()[0]\n",
    "                            Gs_temp[l][k] = Gs_temp[k][l]\n",
    "\n",
    "                          \n",
    "                if args.msvd:\n",
    "                    ide = url2id[name.split(os.sep)[-1].split('.')[0]]\n",
    "                else:\n",
    "                    ide = name.split(os.sep)[-1].split('.')[0]\n",
    "                f.create_dataset(ide+'-'+str(idx_grp), data = Gs_temp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}