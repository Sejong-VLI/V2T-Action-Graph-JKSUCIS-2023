{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce7bdaf1-586a-4ad3-9d58-171ec4eaf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import h5py\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from itertools import permutations\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6a684-6266-455e-90c1-e853be3d175b",
   "metadata": {},
   "source": [
    "## Generate Spatio Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68309640-6303-4d3f-abc9-851ef59f6ca3",
   "metadata": {},
   "source": [
    "#### Path Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d8fa006-03ad-49eb-9893-cda586ae521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument\n",
    "class args:\n",
    "    msvd = True # for MSR-VTT change this to False\n",
    "    num_features = 400\n",
    "    num_features_logits = 1024\n",
    "    slice_framepos=2\n",
    "    root ='./'\n",
    "    dset ='../' # Dataset root\n",
    "    max_frames = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "330491ad-7f3e-4843-af77-4ef843470a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./model/i3d/i3d.ipynb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63209b7e-549c-4657-b48a-eb5b8d597a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initiate I3D model\n",
    "i3d = InceptionI3d(400, in_channels=3)\n",
    "\n",
    "# Pretrained model can be downloaded from here: https://github.com/piergiaj/pytorch-i3d\n",
    "i3d.load_state_dict(torch.load(os.path.join(args.root, 'pretrained', 'rgb_imagenet.pt')))\n",
    "i3d = i3d.to(device)\n",
    "i3d.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b0ce5-a44d-45ad-bc98-5292f7c3c036",
   "metadata": {},
   "source": [
    "#### Frame Preprocessing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb959fd1-a457-4b1c-97cf-819b69e50bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "# Center crop transformation\n",
    "data_transform_i3d = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])\n",
    "\n",
    "# Frame sampling, converting video to frame tensor\n",
    "def video2tensor(video_file, sample_fp=1, start_time=None, end_time=None):\n",
    "    '''Reading video file and return it as tensor\n",
    "    '''\n",
    "    if start_time is not None or end_time is not None:\n",
    "        assert isinstance(start_time, int) and isinstance(end_time, int) \\\n",
    "               and start_time > -1 and end_time > start_time\n",
    "    assert sample_fp > -1\n",
    "\n",
    "    # Samples a frame sample_fp X frames.\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "   \n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    total_duration = (frameCount + fps - 1) // fps\n",
    "    start_sec, end_sec = 0, total_duration\n",
    "    \n",
    "    interval = 1\n",
    "    if sample_fp > 0:\n",
    "        interval = fps // sample_fp\n",
    "    else:\n",
    "        sample_fp = fps\n",
    "    if interval == 0: interval = 1\n",
    "    \n",
    "    inds = [ind for ind in np.arange(0, fps, interval)]\n",
    "    inds_all = [ind for ind in np.arange(0, fps, 1)]\n",
    "    assert len(inds) >= sample_fp\n",
    "    inds = inds[:sample_fp]\n",
    "    inds = set(inds)\n",
    "    ret = True\n",
    "    images,images_i3d, included = [], [], []\n",
    "    c = 0\n",
    "    sampled_indexes = []\n",
    "    for sec in np.arange(start_sec, end_sec + 1):\n",
    "        if not ret: break\n",
    "        for ia in inds_all:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil = Image.fromarray(frame_rgb).convert(\"RGB\")\n",
    "            if ia in inds:\n",
    "                sampled_indexes.append(c)\n",
    "                images.append(data_transform(pil))\n",
    "            images_i3d.append(data_transform_i3d(pil))\n",
    "            c+=1\n",
    "\n",
    "    cap.release()\n",
    "    tensor_obj = None\n",
    "    if len(images) > 0:\n",
    "        video_data = torch.tensor(np.stack(images))\n",
    "        # Process raw data section\n",
    "        tensor_size = video_data.size()\n",
    "        \n",
    "        tensor_obj = video_data.view(-1, 1, tensor_size[-3], tensor_size[-2], tensor_size[-1])\n",
    "        \n",
    "        video_data_i3d = torch.tensor(np.stack(images_i3d))\n",
    "        # Process raw data section\n",
    "        tensor_size = video_data_i3d.size()\n",
    "        tensor_i3d = video_data_i3d.view(-1, 1, tensor_size[-3], tensor_size[-2], tensor_size[-1])\n",
    "    else:\n",
    "        video_data = torch.zeros(1)\n",
    "\n",
    "    return tensor_obj, tensor_i3d, sampled_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a2dd43-0fd7-47b2-9715-44cc37630e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSVD\n",
    "if args.msvd:\n",
    "    dset_path = os.path.join(os.path.join(args.dset,'dataset'),'MSVD')\n",
    "    \n",
    "    features_path = os.path.join(dset_path,'raw') # Raw uncompressed videos .avi    \n",
    "    name_list = glob.glob(features_path+os.sep+'*')\n",
    "\n",
    "    url2id = {}\n",
    "    data_path =os.path.join(os.path.join(dset_path,'captions','youtube_mapping.txt'))\n",
    "    for line in open(data_path,'r').readlines():\n",
    "        url2id[line.strip().split(' ')[0]] = line.strip().split(' ')[-1]\n",
    "        \n",
    "    \n",
    "    path_to_saved_models = \"extracted/msvd\"\n",
    "    pathlib.Path(path_to_saved_models).mkdir(parents=True, exist_ok=True)\n",
    "    save_file = path_to_saved_models+'/<Desired file name>.hdf5'\n",
    "\n",
    "# MSR-VTT\n",
    "else:\n",
    "    dset_path = os.path.join(os.path.join(args.dset,'dataset'),'MSRVTT')\n",
    "    features_path = os.path.join(dset_path,'raw') # Raw uncompressed videos .avi   \n",
    "\n",
    "    name_list = glob.glob(features_path+os.sep+'*')\n",
    "    path_to_saved_models = \"extracted/msrvtt\"\n",
    "    pathlib.Path(path_to_saved_models).mkdir(parents=True, exist_ok=True)\n",
    "    save_file = path_to_saved_models+'/<Desired file name>.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5016a1a-c241-47e2-832e-99de4c8ea939",
   "metadata": {},
   "source": [
    "#### Spatial Graph File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dbda3a1-d58e-4ebc-bda7-9effc3e49a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node feature location\n",
    "FILE_GRID = \"<Path to the extracted grid node features>\" # Output of notebook \"grid_node_theta_1_feature_extractor.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28dd5e03-c275-4c96-9355-9c3512c7e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PATCHES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a5deb-5a47-479e-8363-15b5523d75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every corresponding sampled frame index from node features, \n",
    "# generate the spatial graph using for every frame_num frames.\n",
    "\n",
    "output_features = []\n",
    "a = 0\n",
    "frame_num = 16\n",
    "action_output = {}\n",
    "counter = 0\n",
    "with torch.no_grad():\n",
    "    with h5py.File(FILE_GRID, 'r') as fg, h5py.File(save_file, 'w') as f:\n",
    "        for name in tqdm(name_list):\n",
    "            tensor_obj, tensor_i3d, sampled_indices = video2tensor(name)\n",
    "            sample_indx =[]\n",
    "            if args.max_frames < tensor_obj.shape[0]:\n",
    "                if args.slice_framepos == 0:\n",
    "                    video_slice = raw_video_slice[:args.max_frames, ...]\n",
    "                elif args.slice_framepos == 1:\n",
    "                    video_slice = raw_video_slice[-args.max_frames:, ...]\n",
    "                else:\n",
    "                    sample_indx = list(np.linspace(0, tensor_obj.shape[0] - 1, num=args.max_frames, dtype=int))\n",
    "                 \n",
    "            else:\n",
    "                sample_indx = list(np.arange(tensor_obj.shape[0]))\n",
    "\n",
    "            if(len(sample_indx)<args.max_frames):\n",
    "                additional = 20-len(sample_indx)\n",
    "                sample_indx += (additional * [-1])\n",
    "            \n",
    "            for idx_grp, i in enumerate(sample_indx):\n",
    "                if args.msvd:\n",
    "                    ide = url2id[name.split(os.sep)[-1].split('.')[0]]\n",
    "                else:\n",
    "                    ide = name.split(os.sep)[-1].split('.')[0]\n",
    "                \n",
    "                zero = np.array([0.0]*args.num_features_logits)\n",
    "                Gs_temp = [[zero]* NUM_PATCHES for m in range(NUM_PATCHES)]\n",
    "                    \n",
    "                if (i==-1):\n",
    "                    f.create_dataset(ide+'-'+str(idx_grp), data = Gs_temp)# for each frame\n",
    "                    continue\n",
    "              \n",
    "                i_i3d = (sampled_indices[i]//frame_num)*frame_num\n",
    "                if len(tensor_i3d)-i_i3d < frame_num:\n",
    "                    i_i3d = len(tensor_i3d)-frame_num\n",
    "                    \n",
    "                curr_batch = tensor_i3d[i_i3d:i_i3d+frame_num,...].unsqueeze(0)\n",
    "                n,video_frame,num,channel,h,w = curr_batch.shape\n",
    "                curr_batch = curr_batch.view(num,video_frame,channel, h, w)\n",
    "                curr_batch = curr_batch.permute(0,2,1,3,4)\n",
    "                \n",
    "                out_logits = i3d.extract_features(curr_batch.to(device))\n",
    "            \n",
    "                out_logits= out_logits[:,:,0,0,0]\n",
    "                out_logits = out_logits.cpu().numpy()\n",
    "                \n",
    "                gr = fg[ide+'-'+str(idx_grp)][:]\n",
    "                for k in range(NUM_PATCHES):\n",
    "                    for l in range(k,NUM_PATCHES):\n",
    "                        sum_k = np.sum(gr[k])\n",
    "                        sum_l = np.sum(gr[l])\n",
    "                        if (sum_k!=0 and sum_l!=0):\n",
    "                            Gs_temp[k][l] = out_logits.tolist()[0]\n",
    "                            Gs_temp[l][k] = Gs_temp[k][l]\n",
    "\n",
    "                if args.msvd:\n",
    "                    ide = url2id[name.split(os.sep)[-1].split('.')[0]]\n",
    "                else:\n",
    "                    ide = name.split(os.sep)[-1].split('.')[0]\n",
    "\n",
    "                f.create_dataset(ide+'-'+str(idx_grp), data = Gs_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
