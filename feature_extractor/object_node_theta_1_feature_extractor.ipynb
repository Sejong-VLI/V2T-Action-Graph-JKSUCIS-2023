{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import h5py\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.ops.roi_align as roi_align\n",
    "import pathlib\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Arguments\n",
    "class args:\n",
    "    msvd = True # or msvd = False for MSR-VTT\n",
    "    slice_framepos=2\n",
    "    dset ='../' # change based on dataset location\n",
    "    max_frames = 20\n",
    "    eval_frame_order =0 \n",
    "    output_dir='pretrained'\n",
    "    cache_dir=''\n",
    "    features_path='..'\n",
    "    msrvtt_csv ='msrvtt.csv'\n",
    "    data_path ='MSRVTT_data.json'\n",
    "    max_words=32\n",
    "    feature_framerate=1\n",
    "    cross_model=\"cross-base\"\n",
    "    local_rank=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/oem/.cache/torch/hub/ultralytics_yolov5_master\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m tqdm>=4.64.0 not found and is required by YOLOv5, attempting auto-update...\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/oem/anaconda3/envs/action_graph_env2/lib/python3.8/site-packages (4.64.0)\n",
      "\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m protobuf<=3.20.1 not found and is required by YOLOv5, attempting auto-update...\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /home/oem/anaconda3/envs/action_graph_env2/lib/python3.8/site-packages (3.20.1)\n",
      "\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m 2 packages updated per /home/oem/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m âš ï¸ \u001B[1mRestart runtime or rerun command for updates to take effect\u001B[0m\n",
      "\n",
      "YOLOv5 ðŸš€ 2022-8-18 Python-3.8.8 torch-1.12.0+cu116 CUDA:0 (NVIDIA RTX A6000, 48685MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5l6.pt to yolov5l6.pt...\n",
      "ERROR: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "Re-attempting https://storage.googleapis.com/ultralytics/yolov5/v6.2/yolov5l6.pt to yolov5l6.pt...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  147M  100  147M    0     0  3875k      0  0:00:38  0:00:38 --:--:-- 5592k\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7f93c80f0a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oem/anaconda3/envs/action_graph_env/lib/python3.8/site-packages/tqdm/std.py\", line 1147, in __del__\n",
      "    self.close()\n",
      "  File \"/home/oem/anaconda3/envs/action_graph_env/lib/python3.8/site-packages/tqdm/notebook.py\", line 286, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l6 summary: 476 layers, 76726332 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load object detection model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5l6', pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import dataloader\n",
    "if args.msvd:\n",
    "    %run ../dataloaders/dataloader_msvd.py import MSVD_Loader\n",
    "else:\n",
    "    %run ../dataloaders/dataloader_msrvtt.py import MSRVTT_RawDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set configuration\n",
    "if args.msvd:\n",
    "\n",
    "    dset_path = os.path.join(os.path.join(args.dset,'dataset'),'MSVD')\n",
    "    features_path = os.path.join(dset_path,'raw') # video .avi    \n",
    "    name_list = glob.glob(features_path+os.sep+'*')\n",
    "    args.features_path = features_path\n",
    "\n",
    "    url2id = {}\n",
    "    data_path =os.path.join(os.path.join(dset_path,'captions','youtube_mapping.txt'))\n",
    "    args.data_path = data_path\n",
    "    for line in open(data_path,'r').readlines():\n",
    "        url2id[line.strip().split(' ')[0]] = line.strip().split(' ')[-1]\n",
    "\n",
    "    path_to_saved_models = \"extracted/msvd\"\n",
    "    pathlib.Path(path_to_saved_models).mkdir(parents=True, exist_ok=True)\n",
    "    save_file = path_to_saved_models+'/MSVD_OBJECT_FEAT_FASTERRCNN_RESNET50.hdf5'\n",
    "    args.max_words =30\n",
    "    \n",
    "else:\n",
    "  \n",
    "    dset_path = os.path.join(os.path.join(args.dset,'dataset'),'MSRVTT')\n",
    "    features_path = os.path.join(dset_path,'raw')\n",
    "    args.features_path = features_path\n",
    "    data_path=os.path.join(dset_path,'MSRVTT_data.json')\n",
    "    args.data_path = data_path\n",
    "    args.msrvtt_csv = os.path.join(dset_path,'msrvtt.csv')\n",
    "    name_list = glob.glob(features_path+os.sep+'*')\n",
    "    \n",
    "    path_to_saved_models = \"extracted/msrvtt\"\n",
    "    pathlib.Path(path_to_saved_models).mkdir(parents=True, exist_ok=True)\n",
    "    save_file = path_to_saved_models+'/MSRVTT_OBJECT_FEAT_FASTERRCNN_RESNET50.hdf5'\n",
    "    args.max_words =73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Feature extractor\n",
    "def save_features(mod, inp, outp):\n",
    "    features.append(outp)\n",
    "\n",
    "# layer_to_hook = 'backbone.body.layer4.2.relu'\n",
    "# layer_to_hook = 'roi_heads.box_roi_pool'\n",
    "\n",
    "layer_to_hook = 'model.11.cv2.act'\n",
    "# layer_to_hook = 'backbone.body.layer4'\n",
    "for name, layer in model.model.model.named_modules():\n",
    "# for name, layer in model.named_modules():\n",
    "    if name == layer_to_hook:\n",
    "        layer.register_forward_hook(save_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video number: 1970\n",
      "Id number: 1970\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "if args.msvd :\n",
    "    videos= MSVD_Loader(\n",
    "        features_path=args.features_path,\n",
    "        max_words=args.max_words,\n",
    "        feature_framerate=args.feature_framerate,\n",
    "        max_frames=args.max_frames,\n",
    "        frame_order=args.eval_frame_order,\n",
    "        slice_framepos=args.slice_framepos,\n",
    "        transform_type = 1,\n",
    "        data_path = args.data_path\n",
    ") \n",
    "else:\n",
    "    videos= MSRVTT_RawDataLoader(\n",
    "        csv_path=args.msrvtt_csv,\n",
    "        features_path=args.features_path,\n",
    "        max_words=args.max_words,\n",
    "        feature_framerate=args.feature_framerate,\n",
    "        max_frames=args.max_frames,\n",
    "        frame_order=args.eval_frame_order,\n",
    "        slice_framepos=args.slice_framepos,\n",
    "        transform_type = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate Object Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1970/1970 [24:18<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "output_features = []\n",
    "threshold = 0.5\n",
    "model.conf = 0.5\n",
    "features = None\n",
    "stop = False\n",
    "list_videoid = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    with h5py.File(save_file, 'w') as f:\n",
    "        for video_id,video,video_mask in tqdm(videos):\n",
    "            if features is not None:\n",
    "                del features\n",
    "            features = []\n",
    "            if (type(video) == bool):\n",
    "                stop = True\n",
    "            if stop:\n",
    "                break\n",
    "\n",
    "            tensor = video[0]\n",
    "\n",
    "            roi_align_out_per_video = []\n",
    "            for i in range(len(tensor)): \n",
    "                input = torch.tensor(tensor[i:i+1]).float()\n",
    "                video_frame,num,channel,h,w = input.shape\n",
    "                input = input.view(video_frame,channel, h, w)\n",
    "\n",
    "                transform = T.ToPILImage()\n",
    "                img = transform(input[0])\n",
    "\n",
    "                output = model(img)\n",
    "\n",
    "                spat_scale = min(features[i].shape[2]/input.shape[2], features[i].shape[3]/input.shape[3])\n",
    "                roi_align_out_per_frame = []\n",
    "                for j, box in enumerate(output.xyxy[0].cpu().numpy()): # for each box\n",
    "                    if len(roi_align_out_per_frame)==9: # max object per frame is 9\n",
    "                        break\n",
    "                    roi_align_out = roi_align(features[i], [output.xyxy[0][:,:4][j:j+1]], output_size=1, spatial_scale=spat_scale, aligned=True)\n",
    "                    roi_align_out_per_frame.append(torch.squeeze(roi_align_out).cpu().numpy())\n",
    "                if len(roi_align_out_per_frame)<9: # add zero padding if less than 5 object\n",
    "                    \n",
    "                    for y in range(len(roi_align_out_per_frame), 9):\n",
    "                        zero_padding = [0]*1024 # length of the roi_align_out is also 1024, hardcoded for now\n",
    "                        roi_align_out_per_frame.append(zero_padding)\n",
    "                \n",
    "                roi_align_out_per_frame = np.stack(roi_align_out_per_frame)\n",
    "                f.create_dataset(video_id+'-'+str(i), data = roi_align_out_per_frame)\n",
    "                del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action_graph_env",
   "language": "python",
   "name": "action_graph_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}