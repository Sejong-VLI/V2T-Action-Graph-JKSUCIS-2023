{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2j6IBHJ_OEI",
    "outputId": "384a33f6-a483-4892-c146-a15a017f35fb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import h5py\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.models as models\n",
    "import torchvision.ops.roi_align as roi_align\n",
    "\n",
    "from modules.until_module import PreTrainedModel, AllGather, CrossEn\n",
    "from modules.module_cross import CrossModel, CrossConfig, Transformer as TransformerClip\n",
    "\n",
    "from modules.module_clip import CLIP, convert_weights\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import pickle\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from modules.modeling import CLIP4Clip\n",
    "from modules.optimization import BertAdam\n",
    "from util import parallel_apply, get_logger\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument\n",
    "class args:\n",
    "    msvd = True # or msvd = False for MSR-VTT\n",
    "    slice_framepos=2\n",
    "    dset ='../' # change based on dataset location\n",
    "    save_path = '../../extracted'\n",
    "    max_frames = 20\n",
    "    eval_frame_order =0 \n",
    "    output_dir='pretrained'\n",
    "    cache_dir=''\n",
    "    \n",
    "    features_path='..'\n",
    "    msrvtt_csv ='msrvtt.csv'\n",
    "    data_path ='MSRVTT_data.json'\n",
    "    max_words=32\n",
    "    feature_framerate=1\n",
    "    cross_model=\"cross-base\"\n",
    "    local_rank=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video number: 0\n",
      "Id number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/anaconda3/envs/py_univl/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#MSVD \n",
    "if args.msvd:\n",
    "\n",
    "    dset_path = os.path.join(os.path.join(args.dset,'dataset'),'MSVD')\n",
    "    features_path = os.path.join(dset_path,'raw') # video .avi    \n",
    "    name_list = glob.glob(features_path+os.sep+'*')\n",
    "    args.features_path = features_path\n",
    "\n",
    "    url2id = {}\n",
    "    data_path =os.path.join(os.path.join(dset_path,'captions','youtube_mapping.txt'))\n",
    "    args.data_path = data_path\n",
    "    for line in open(data_path,'r').readlines():\n",
    "        url2id[line.strip().split(' ')[0]] = line.strip().split(' ')[-1]\n",
    "\n",
    "    path_to_saved_models = \"extracted/msvd\"\n",
    "    pathlib.Path(path_to_saved_models).mkdir(parents=True, exist_ok=True)\n",
    "    save_file = path_to_saved_models+'/MSVD_Clip4Clip_features.pickle'\n",
    "    args.max_words =30\n",
    "    \n",
    "    # Load video to dataloader\n",
    "    %run ../dataloaders/dataloader_msvd.py import MSVD_Loader\n",
    "    \n",
    "    videos= MSVD_Loader(\n",
    "        data_path=args.data_path,\n",
    "        features_path=args.features_path,\n",
    "        max_words=args.max_words,\n",
    "        feature_framerate=args.feature_framerate,\n",
    "        max_frames=args.max_frames,\n",
    "        frame_order=args.eval_frame_order,\n",
    "        slice_framepos=args.slice_framepos,\n",
    "        transform_type = 0,\n",
    "    ) \n",
    "#MSR-VTT    \n",
    "else:\n",
    "  \n",
    "    dset_path = os.path.join(os.path.join(args.dset,'dataset'),'MSRVTT')\n",
    "    features_path = os.path.join(dset_path,'raw') \n",
    "    args.features_path = features_path\n",
    "    data_path=os.path.join(dset_path,'MSRVTT_data.json')\n",
    "    args.data_path = data_path\n",
    "    args.msrvtt_csv = os.path.join(dset_path,'msrvtt.csv')\n",
    "    name_list = glob.glob(features_path+os.sep+'*')\n",
    "    \n",
    "    path_to_saved_models = \"extracted/msrvtt\"\n",
    "    pathlib.Path(path_to_saved_models).mkdir(parents=True, exist_ok=True)\n",
    "    save_file = path_to_saved_models+'/MSRVTT_Clip4Clip_features.pickle'\n",
    "    args.max_words =73\n",
    "    \n",
    "    #Load video to dataloader\n",
    "    %run ../dataloaders/dataloader_msrvtt.py import MSRVTT_RawDataLoader\n",
    "    videos= MSRVTT_RawDataLoader(\n",
    "        csv_path=args.msrvtt_csv,\n",
    "        features_path=args.features_path,\n",
    "        max_words=args.max_words,\n",
    "        feature_framerate=args.feature_framerate,\n",
    "        max_frames=args.max_frames,\n",
    "        frame_order=args.eval_frame_order,\n",
    "        slice_framepos=args.slice_framepos,\n",
    "        transform_type = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CLIP4Clip pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch = 1\n",
    "model_file=  os.path.join(args.output_dir, \"pytorch_model.bin.{}\".format(epoch-1))\n",
    "model_state_dict = torch.load(model_file, map_location='cpu')\n",
    "cache_dir = args.cache_dir if args.cache_dir else os.path.join(str(PYTORCH_PRETRAINED_BERT_CACHE), 'distributed')\n",
    "model = CLIP4Clip.from_pretrained(args.cross_model, cache_dir=cache_dir, state_dict=model_state_dict, task_config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = model.clip.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract clip features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "clip.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    data ={}\n",
    "    stop = False\n",
    "    with open(save_file, 'wb') as handle:\n",
    "\n",
    "        for i in tqdm(range(len(videos))):\n",
    "\n",
    "            video_id,video,video_mask = videos[i]\n",
    "\n",
    "            tensor = video[0]\n",
    "            tensor = tensor[video_mask[0]==1,:]\n",
    "            tensor = torch.as_tensor(tensor).float()\n",
    "            video_frame,num,channel,h,w = tensor.shape\n",
    "            tensor = tensor.view(video_frame*num, channel, h, w)\n",
    "\n",
    "            video_frame,channel,h,w = tensor.shape\n",
    "\n",
    "\n",
    "            output = clip.encode_image(tensor.to(device), video_frame=video_frame).float().to(device)\n",
    "            output = output.detach().cpu().numpy()\n",
    "            data[video_id]=output\n",
    "\n",
    "            del output\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2D_Feature_Branch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
